{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preprocess Inference Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "import os\n",
    "\n",
    "\n",
    "path = os.path.abspath(os.path.join(os.getcwd(), \"../../\"))\n",
    "sys.path.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deployment.model_monitoring.inference_log import process_request, read_inference_log_from_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get Environmental Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get enviornment variables\n",
    "dbutils.widgets.text(\"env\", \"dev\")\n",
    "dbutils.widgets.text(\"catalog_name\", \"devaiml\")\n",
    "dbutils.widgets.text(\"schema_name\", \"occupancy_project\")\n",
    "dbutils.widgets.text(\"inference_table_name\", \"dev_occupancy_inference_payload\") \n",
    "\n",
    "env = dbutils.widgets.get(\"env\")\n",
    "catalog_name = dbutils.widgets.get(\"catalog_name\")\n",
    "schema_name = dbutils.widgets.get(\"schema_name\")\n",
    "inference_table_name = dbutils.widgets.get(\"inference_table_name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Execute Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference table to process\n",
    "table_name = f\"{catalog_name}.{schema_name}.{inference_table_name}\"\n",
    "# Process the inference table\n",
    "print(f\"Processing inference table: {table_name}\")\n",
    "# get inference logs from table\n",
    "inference_logs = read_inference_log_from_table(table_name)\n",
    "processed_df = process_request(inference_logs)\n",
    "\n",
    "# save processed logs to table\n",
    "processed_df.write.mode(\"append\").saveAsTable(f\"{catalog_name}.{schema_name}.processed_inference_logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable CDF monitoring on processed logs table\n",
    "spark.sql(f\"ALTER TABLE {catalog_name}.{schema_name}.processed_inference_logs SET TBLPROPERTIES (delta.enableChangeDataFeed = true)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
